{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Se ha notado que hay ciertos profesores que no consiguen acercar las adaptaciones necesarias a sus alumnos. El objetivo de nuestra tecnología sería predecir el nivel académico que va a desempeñar el alumno para estar más pendientes de aquellos alumnos que lo necesiten.\n",
    "\n",
    "Para ello, se va a utilizar un dataset que contiene información sobre los alumnos y su rendimiento académico. Se va a realizar un análisis exploratorio de los datos para entender mejor la información que contienen y poder realizar un modelo predictivo que nos permita predecir el nivel académico de los alumnos.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "## Columnas del dataset que vamos a usar\n",
    "- `Gender`: Género del alumno\n",
    "- `Age` : Edad del alumno\n",
    "- `Study Hour/Day` : Horas de estudio al día\n",
    "- `Learning mode` : Modalidad de aprendizaje\n",
    "- `How many hour do you spent daily in social media?` : Horas diarias en redes sociales\n",
    "- `Average attendance` : Asistencia media\n",
    "- `With whom you are living?` : Con quién vive\n",
    "- `What was your previous SGPA?` : Nota media anterior\n",
    "- `What is your monthly family income?` : Ingresos familiares\n",
    "\n",
    "Lo primero que hemos hecho ha sido renombrar algunas de las columnas ya que no estaban muy bien redactadas. Además, hemos eliminado las columnas que no vamos a utilizar en nuestro análisis. \n",
    "\n",
    "Lo siguiente que hemos hecho ha sido eliminar las filas que contienen valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza del dataset de los datos de los estudiantes.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "#Cargamos el dataset\n",
    "\n",
    "data = pd.read_csv('Students_Performance_data_set.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data.shape\n",
    "\n",
    "#Renombramos las columnas que nos interesan\n",
    "\n",
    "new_columns = {'Gender':'Gender', 'Age':'Age', 'Study Hour/day':'Study time', 'Learning mode':'Learning mode', 'How many hour do you spent daily in social media?':'Time on social media', 'Average attendance on class':'Average attendance', 'With whom you are living with?':'Cohabitants', 'What was your previous SGPA?':'Previous SGPA', 'What is your current CGPA?':'Current CPGA', 'What is your monthly family income?':'Family income'}\n",
    "\n",
    "data.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "#Seleccionamos las columnas que nos interesan\n",
    "\n",
    "columns_of_interest = ['Gender', 'Age', 'Study time', 'Learning mode', 'Time on social media', 'Average attendance', 'Cohabitants', 'Previous SGPA', 'Current CPGA',  'Family income']\n",
    "\n",
    "data = data[columns_of_interest]\n",
    "\n",
    "#Eliminamos las filas con valores nulos\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización de Age\n",
    "Hemos usado la funcion unique() para ver que tipos de valores pueden tomar estos datos. Hemos apuntados aquellos que no son numéricos o dan un rango y hemos decidido cambiarlos a numéricos. Esto se puede ver el bloque de código siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'].unique()\n",
    "\n",
    "# notamos que hay 6 valores que se salen de un numero como tal asi que usamos un replace para cambiarlos a un valor que no afecte el analisis\n",
    "data['Age'] = data['Age'].replace({\n",
    "    '21+' : 21,\n",
    "    '23.6' : 23,\n",
    "    '20+' : 20,\n",
    "    '22+' : 22,\n",
    "    '24+' : 24,\n",
    "    '20 years 6 months' : 20\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarizacion de tiempos\n",
    "\n",
    "Lo que hemos hecho en el codigo que sigue este bloque de markdown es estandarizar los tiempos para poder tener los datos correctos tanto como para el Study Time como para el Time on Social Media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Usamos la función unique para ver los valores únicos de la columna y asi saber como estandarizarlos\n",
    "# print(data['Study time'].unique())\n",
    "\n",
    "def standarise_time(time): # sigue teniendo un error en la función cuando tiene un valor de minutos y otro seguido de horas\n",
    "    # we extract the number and hour/minute from the string\n",
    "    hours_numeric = re.findall(r'\\d+', str(time))\n",
    "    \n",
    "    # extract the numeric value for the hours\n",
    "    if 'hours' in str(time).lower() or 'hour' in str(time).lower() or 'hrs' in str(time).lower() or 'hr' in str(time).lower():\n",
    "        if hours_numeric:\n",
    "            return int(hours_numeric[0])\n",
    "        else:\n",
    "            return None\n",
    "    # extract the numeric value for the minutes and convert them to hours convert to lower case to avoid case sensitivity\n",
    "    elif 'minutes' in str(time).lower() or 'minute' in str(time).lower() or 'mins' in str(time).lower() or 'min' in str(time).lower() :\n",
    "        if hours_numeric:\n",
    "            return int(hours_numeric[0])/60\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Some of the data is written in a range format, so we need to calculate the average\n",
    "    elif '-' in str(time) or 'to' in str(time).lower() or 'or' in str(time).lower() or '/' in str(time):\n",
    "        # we calculate the average\n",
    "        if len(hours_numeric) == 2:\n",
    "            return (int(hours_numeric[0]) + int(hours_numeric[1]))/2\n",
    "        else:\n",
    "            return None\n",
    "    # if the data is in a numeric format, we just return the number\n",
    "    elif hours_numeric:\n",
    "        return int(hours_numeric[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "data['Study stand'] = data['Study time'].apply(standarise_time)\n",
    "## TODO si queremos inferir aquellos datos que no se pudieron estandarizar en vez de hacer la media guarra\n",
    "study_mean = data['Study stand'].mean()\n",
    "data['Study stand'] = data['Study stand'].fillna(study_mean)\n",
    "\n",
    "\n",
    "data['Social stand'] = data['Time on social media'].apply(standarise_time)\n",
    "## TODO si queremos inferir aquellos datos que no se pudieron estandarizar en vez de hacer la media guarra\n",
    "social_mean = data['Social stand'].mean()\n",
    "data['Social stand'] = data['Social stand'].fillna(social_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarizacion de Attendance\n",
    "\n",
    "En el siguiente bloque de codigo hemos implementado la funcion standarise_attendance(value) convirtiendo los datos para que siguan el mismo formato compuesto por un numero y ya esta. Para aquellos valores que sean NaN, cogeremos el valor medio de la columna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarise_attendance(attendance):\n",
    "    \n",
    "    # primero quitamos todos los caracteres que no sean alfanuméricos o un signo de porcentaje\n",
    "    value = re.sub(r'[^a-zA-Z0-9%]', '', str(attendance))\n",
    "    \n",
    "    if '%' in value:\n",
    "        value = re.search(r'\\d+', value).group()\n",
    "        value = int(value)\n",
    "    # si no es un porcentaje intentar convertirlo a un número\n",
    "    else:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except ValueError:\n",
    "            value = float('nan')\n",
    "            \n",
    "    # asegurarse de que el valor esté entre 0 y 100\n",
    "    value = min(max(value, 0), 100)\n",
    "    return value\n",
    "\n",
    "data['Attendance stand'] = data['Average attendance'].apply(standarise_attendance)\n",
    "\n",
    "## TODO si queremos inferir aquellos datos que no se pudieron estandarizar en vez de hacer la media guarra\n",
    "attendance_mean = data['Attendance stand'].mean()\n",
    "data['Attendance stand'] = data['Attendance stand'].fillna(attendance_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarizacion de CGPA y SGPA\n",
    "\n",
    "En este caso en vez de definir una funcion como todos los datos que estan en formato numerico son correctos usamos to_numeric() de pandas, cuando se encuentre con una valor que no se puede convertir a numerico devolvemos NaN con errors='coerce'. Para aquellos datos que sean NaN, hacer la media de los datos que si que se pueden convertir a numerico y rellenar los NaN con esa media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Current CPGA stand\"] = pd.to_numeric(data[\"Current CPGA\"], errors='coerce')\n",
    "## TODO si queremos inferir aquellos datos que no se pudieron estandarizar en vez de hacer la media guarra\n",
    "cpga_mean = data[\"Current CPGA stand\"].mean()\n",
    "data[\"Current CPGA stand\"].fillna(cpga_mean, inplace=True)\n",
    "\n",
    "\n",
    "data[\"Previous SGPA stand\"] = pd.to_numeric(data[\"Previous SGPA\"], errors='coerce')\n",
    "## TODO si queremos inferir aquellos datos que no se pudieron estandarizar en vez de hacer la media guarra\n",
    "sgpa_mean = data[\"Previous SGPA stand\"].mean()\n",
    "data[\"Previous SGPA stand\"].fillna(sgpa_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandandarizacion de Family Income\n",
    "Como siempre usamos data.unique() para ver los valores que toman los datos y de ahi decidir como vamos a tratar los datos que consideramos \"anomalos\" o mal escritos.\n",
    "\n",
    "1. Convertir de otras monedas y otras magnitudes a bdt 10E\n",
    "2. Transformar los rangos a un valor numerico\n",
    "3. Quitar el BDT que es la moneda de Bangladesh\n",
    "4. Dejar numeros limpios. Alguna gente a puesto valores como \"Approximately 30000\". Lo hemos convertido al valor numerico\n",
    "5. Cambiar los valores que no son numericos a la media de income del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transform currency to bdt 10E\n",
    "def convert_to_bdt_standard(income):\n",
    "    if isinstance(income, str) and '$' in income.lower():\n",
    "        number = re.findall(r'\\d+', income)\n",
    "        if number:\n",
    "            return int(number[0])*109.7 #Conversion de dolar a taka 10.04.2024\n",
    "    if isinstance(income, str) and 'lac' in income.lower():\n",
    "        number = re.findall(r'\\d+', income)\n",
    "        if number:\n",
    "            return int(number[0])*100000 #Conversion de lakh(lac) a estandard\n",
    "    if isinstance(income, str) and 'k' in income.lower():\n",
    "        number = re.findall(r'\\d+', income)\n",
    "        if number:\n",
    "            return int(number[0])*1000\n",
    "    return income\n",
    "\n",
    "# transformamos rangos a la media\n",
    "def remove_range(income):\n",
    "    if isinstance(income, str) and ('-' in income or '/' in income) :\n",
    "        numbers = re.findall(r'\\d+', income)\n",
    "        if len(numbers) == 2:\n",
    "            return (int(numbers[0]) + int(numbers[1]))/2\n",
    "    return income\n",
    "    \n",
    "# quitando el BDT\n",
    "def remove_BDT(income):\n",
    "    if isinstance(income, str) and ('bdt' in income.lower() or 'DBT' in income or 'BTD' in income or 'taka' in income):\n",
    "        number = re.findall(r'\\d+', income)\n",
    "        if number:\n",
    "            return int(number[0])\n",
    "    return income\n",
    "\n",
    "def clean_numbers(income):\n",
    "    if isinstance(income, str):\n",
    "        number = re.findall(r'\\d+', income)\n",
    "        if number:\n",
    "            return number[0]\n",
    "    return income\n",
    "\n",
    "# apply the function to the column\n",
    "data['Family income stand'] = data['Family income'].apply(convert_to_bdt_standard)\n",
    "data['Family income stand'] = data['Family income stand'].apply(remove_range)\n",
    "data['Family income stand'] = data['Family income stand'].apply(remove_BDT)\n",
    "data['Family income stand'] = data['Family income stand'].apply(clean_numbers)\n",
    "data['Family income stand'] = pd.to_numeric(data['Family income stand'], errors='coerce')\n",
    "\n",
    "## TODO si queremos inferir aquellos datos que no se pudieron estandarizar en vez de hacer la media guarra\n",
    "mean_income = data['Family income stand'].mean()\n",
    "data['Family income stand'] = data['Family income stand'].fillna(mean_income)\n",
    "data['Family income stand'] = data['Family income stand'].astype(int) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion de datos\n",
    "\n",
    "Convertimos los numeros a numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age stand</th>\n",
       "      <th>Study stand</th>\n",
       "      <th>Learning mode</th>\n",
       "      <th>Social stand</th>\n",
       "      <th>Attendance stand</th>\n",
       "      <th>Cohabitants</th>\n",
       "      <th>Previous SGPA stand</th>\n",
       "      <th>Current CPGA stand</th>\n",
       "      <th>Family income stand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Offline</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.64</td>\n",
       "      <td>32500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Offline</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.53</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Offline</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>Family</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.89</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Online</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.336275</td>\n",
       "      <td>Family</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.50</td>\n",
       "      <td>207239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Offline</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.65</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Online</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.77</td>\n",
       "      <td>180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Offline</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.22</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Offline</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Family</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.78</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Offline</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.52</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Online</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.88</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age stand  Study stand Learning mode  Social stand  \\\n",
       "7     Female         22          2.0       Offline           2.0   \n",
       "11      Male         22          3.0       Offline           2.0   \n",
       "15      Male         20          2.0       Offline           1.0   \n",
       "18      Male         21          1.0        Online           3.0   \n",
       "20    Female         21          3.0       Offline           2.0   \n",
       "...      ...        ...          ...           ...           ...   \n",
       "1189  Female         20          1.0        Online           2.0   \n",
       "1190    Male         23          4.0       Offline           4.0   \n",
       "1191    Male         22          3.0       Offline           2.0   \n",
       "1192  Female         25          5.0       Offline           3.0   \n",
       "1193  Female         23          3.0        Online           5.0   \n",
       "\n",
       "      Attendance stand Cohabitants  Previous SGPA stand  Current CPGA stand  \\\n",
       "7           100.000000    Bachelor                 3.80                3.64   \n",
       "11           90.000000    Bachelor                 3.40                3.53   \n",
       "15           95.000000      Family                 3.93                3.89   \n",
       "18           88.336275      Family                 3.10                3.50   \n",
       "20           96.000000    Bachelor                 3.81                3.65   \n",
       "...                ...         ...                  ...                 ...   \n",
       "1189         46.000000    Bachelor                 2.65                3.77   \n",
       "1190        100.000000    Bachelor                 2.50                2.22   \n",
       "1191        100.000000      Family                 1.56                2.78   \n",
       "1192        100.000000    Bachelor                 1.40                2.52   \n",
       "1193        100.000000    Bachelor                 1.34                2.88   \n",
       "\n",
       "      Family income stand  \n",
       "7                   32500  \n",
       "11                  20000  \n",
       "15                  30000  \n",
       "18                 207239  \n",
       "20                  30000  \n",
       "...                   ...  \n",
       "1189               180000  \n",
       "1190               200000  \n",
       "1191               200000  \n",
       "1192               210000  \n",
       "1193               250000  \n",
       "\n",
       "[1042 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                 0\n",
      "Age stand              0\n",
      "Study stand            0\n",
      "Learning mode          0\n",
      "Social stand           0\n",
      "Attendance stand       0\n",
      "Cohabitants            0\n",
      "Previous SGPA stand    0\n",
      "Current CPGA stand     0\n",
      "Family income stand    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['Family income stand'] = pd.to_numeric(data['Family income stand'], errors='coerce')\n",
    "data['Attendance stand'] = pd.to_numeric(data['Attendance stand'], errors='coerce')\n",
    "data['Study stand'] = pd.to_numeric(data['Study stand'], errors='coerce')\n",
    "data['Social stand'] = pd.to_numeric(data['Social stand'], errors='coerce')\n",
    "data['Age stand'] = pd.to_numeric(data['Age'], errors='coerce')\n",
    "\n",
    "## creamos un nuevo dataset con las columnas que nos interesan\n",
    "new_columns = ['Gender', 'Age stand', 'Study stand', 'Learning mode', 'Social stand', 'Attendance stand', 'Cohabitants', 'Previous SGPA stand', 'Current CPGA stand', 'Family income stand']\n",
    "\n",
    "data = data[new_columns]\n",
    "\n",
    "## data.dropna()\n",
    "display(data)\n",
    "\n",
    "## mostrar numero de valores nulos\n",
    "print(data.isnull().sum())\n",
    "\n",
    "data.to_csv('Students_Performance_data_set_cleaned.csv', index=False)\n",
    "dataCL = pd.read_csv('Students_Performance_data_set_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación datos para entrenamieto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11673/3202329290.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  dataCL.data = dataCL[data_columns]\n",
      "/tmp/ipykernel_11673/3202329290.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  dataCL.target = dataCL[data_target]\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['Gender', 'Age stand', 'Study stand', 'Learning mode', 'Social stand', 'Attendance stand', 'Cohabitants', 'Previous SGPA stand', 'Family income stand']\n",
    "data_target = ['Current CPGA stand']\n",
    "dataCL.data = dataCL[data_columns]\n",
    "dataCL.target = dataCL[data_target]\n",
    "\n",
    "X_train = dataCL.data[:-20]\n",
    "y_train = dataCL.target[:-20]\n",
    "X_test = dataCL.data[-20:]\n",
    "y_test = dataCL.target[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Female'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11673/1936460171.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediccion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 )\n\u001b[1;32m   1473\u001b[0m             ):\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnearest\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    477\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 )\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         raise ValueError(\n\u001b[1;32m   1260\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m         )\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1264\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    994\u001b[0m                         )\n\u001b[1;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m                 raise ValueError(\n\u001b[1;32m   1000\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Female'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "print(\"Prediccion\")\n",
    "print(prediction)\n",
    "print(\"Test\")\n",
    "print(y_test)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "\n",
    "decision_tree = decision_tree.fit(X_train, y_train)\n",
    "r = export_text(decision_tree, feature_names=data.feature_names)\n",
    "print(r)\n",
    "decision_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear', random_state=0)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "model.score(X_test, y_test) ## no se lo que es model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=100, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300, verbose=True).fit(X_train, y_train)\n",
    "clf.predict_proba(X_test[:1])\n",
    "y_pred = clf.predict(X_test[:, :])\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
